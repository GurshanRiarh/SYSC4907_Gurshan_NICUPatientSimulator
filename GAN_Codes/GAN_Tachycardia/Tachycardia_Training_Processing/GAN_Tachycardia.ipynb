{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BPM sequences from the new tachycardia dataset\n",
    "file_path = \"/home/Gurshan.R/Documents/GitHub/SYSC4907_Capstone/GAN_Tachycardia/Scaled_CSV_DATA/BPM_Tachycardia_8hr_5min_Neonatal.csv\"\n",
    "df = pd.read_csv(file_path, header=None)  # Assuming no column headers\n",
    "\n",
    "# Convert data into NumPy array\n",
    "data = df.to_numpy(dtype=np.float32)  # Shape: (num_samples, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize BPM data (to [0,1] range for GAN training)\n",
    "min_val, max_val = data.min(), data.max()\n",
    "data_normalized = (data - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensor\n",
    "data_normalized = torch.tensor(data_normalized, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAN model with 96-dimensional input/output\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        return self.model(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensions\n",
    "noise_dim = 10  # Random noise input size\n",
    "output_dim = 96  # Each output is a 96-point sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GAN models\n",
    "generator = Generator(noise_dim, output_dim).to(device)\n",
    "discriminator = Discriminator(output_dim).to(device)\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 5000\n",
    "batch_size = 16\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    discriminator.zero_grad()\n",
    "    idx = torch.randint(0, data_normalized.size(0), (batch_size,))\n",
    "    real_data = data_normalized[idx].to(device)\n",
    "    real_loss = criterion(discriminator(real_data), real_labels)\n",
    "\n",
    "    noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "    fake_data = generator(noise).detach()\n",
    "    fake_loss = criterion(discriminator(fake_data), fake_labels)\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    # Train Generator\n",
    "    generator.zero_grad()\n",
    "    noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "    fake_data = generator(noise)\n",
    "    g_loss = criterion(discriminator(fake_data), real_labels)\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch [{epoch}/{epochs}] D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic BPM sequences\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(10, noise_dim).to(device)  # Generate 10 synthetic 96-point sequences\n",
    "    synthetic_data = generator(noise).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize the synthetic data back to original BPM range\n",
    "synthetic_data_denormalized = synthetic_data * (max_val - min_val) + min_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic data\n",
    "synthetic_output_file = \"/home/Gurshan.R/Documents/GitHub/SYSC4907_Capstone/GAN_Tachycardia/Synthetic_CSV_DATA/BPM_Tachycardia_8hr_5min_Synthetic.csv\"\n",
    "np.savetxt(synthetic_output_file, synthetic_data_denormalized, delimiter=\",\")\n",
    "\n",
    "print(f\"Synthetic BPM data saved: {synthetic_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real vs synthetic data for comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(synthetic_data_denormalized[0], label=\"Synthetic BPM\", linestyle=\"--\", color=\"red\", alpha=0.8)\n",
    "plt.plot(data[:10].mean(axis=0), label=\"Real BPM (Average)\", linestyle=\"-\", color=\"blue\", alpha=0.6)\n",
    "plt.xlabel(\"Time Steps (5-min intervals)\")\n",
    "plt.ylabel(\"BPM\")\n",
    "plt.title(\"Comparison of Real and Synthetic Neonatal Tachycardia BPM Data\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained generator\n",
    "torch.save(generator.state_dict(), \"/home/Gurshan.R/Documents/GitHub/SYSC4907_Capstone/GAN_Tachycardia/trained_generator_Tachycardia.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Tachycardia Episode Evaluation Code -----\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Define a tachycardia threshold (adjust this value as needed)\n",
    "tachy_threshold = 160\n",
    "\n",
    "def extract_tachycardia_episodes(sequence, threshold):\n",
    "    \"\"\"\n",
    "    Extract contiguous episodes where BPM is above the tachycardia threshold.\n",
    "    Each episode is a list of BPM values.\n",
    "    \"\"\"\n",
    "    episodes = []\n",
    "    current_episode = []\n",
    "    for bpm in sequence:\n",
    "        if bpm > threshold:\n",
    "            current_episode.append(bpm)\n",
    "        else:\n",
    "            if current_episode:\n",
    "                episodes.append(current_episode)\n",
    "                current_episode = []\n",
    "    if current_episode:\n",
    "        episodes.append(current_episode)\n",
    "    return episodes\n",
    "\n",
    "# --- Evaluate Episodes in Real Data ---\n",
    "# 'data' is your original real data loaded from the CSV (shape: [num_samples, 96])\n",
    "real_tachy_metrics = []  # Each element: (duration in timesteps, maximum BPM)\n",
    "for sequence in data:\n",
    "    episodes = extract_tachycardia_episodes(sequence, tachy_threshold)\n",
    "    for ep in episodes:\n",
    "        duration = len(ep)              # Duration in number of 5-min timesteps\n",
    "        max_bpm = max(ep)               # Maximum BPM during the episode\n",
    "        real_tachy_metrics.append((duration, max_bpm))\n",
    "\n",
    "if real_tachy_metrics:\n",
    "    real_tachy_metrics = np.array(real_tachy_metrics)\n",
    "    real_durations = real_tachy_metrics[:, 0]\n",
    "    real_max_bpm = real_tachy_metrics[:, 1]\n",
    "    print(f\"Real Tachycardia Episodes: Count = {len(real_durations)}, \"\n",
    "          f\"Mean Duration = {np.mean(real_durations):.2f} timesteps, \"\n",
    "          f\"Mean Max BPM = {np.mean(real_max_bpm):.2f}\")\n",
    "else:\n",
    "    print(\"No tachycardia episodes found in real data.\")\n",
    "\n",
    "# --- Evaluate Episodes in Synthetic Data ---\n",
    "synthetic_tachy_metrics = []  # Each element: (duration, maximum BPM)\n",
    "for sequence in synthetic_data_denormalized:\n",
    "    episodes = extract_tachycardia_episodes(sequence, tachy_threshold)\n",
    "    for ep in episodes:\n",
    "        duration = len(ep)\n",
    "        max_bpm = max(ep)\n",
    "        synthetic_tachy_metrics.append((duration, max_bpm))\n",
    "\n",
    "if synthetic_tachy_metrics:\n",
    "    synthetic_tachy_metrics = np.array(synthetic_tachy_metrics)\n",
    "    synthetic_durations = synthetic_tachy_metrics[:, 0]\n",
    "    synthetic_max_bpm = synthetic_tachy_metrics[:, 1]\n",
    "    print(f\"Synthetic Tachycardia Episodes: Count = {len(synthetic_durations)}, \"\n",
    "          f\"Mean Duration = {np.mean(synthetic_durations):.2f} timesteps, \"\n",
    "          f\"Mean Max BPM = {np.mean(synthetic_max_bpm):.2f}\")\n",
    "else:\n",
    "    print(\"No tachycardia episodes found in synthetic data.\")\n",
    "\n",
    "# --- Quantitative Comparison Using KS Tests ---\n",
    "if real_tachy_metrics.size > 0 and synthetic_tachy_metrics.size > 0:\n",
    "    # Compare episode durations\n",
    "    duration_ks_stat, duration_ks_p = ks_2samp(real_durations, synthetic_durations)\n",
    "    # Compare maximum BPM during episodes\n",
    "    max_bpm_ks_stat, max_bpm_ks_p = ks_2samp(real_max_bpm, synthetic_max_bpm)\n",
    "    \n",
    "    print(f\"KS test on episode durations: Statistic = {duration_ks_stat:.4f}, p-value = {duration_ks_p:.4f}\")\n",
    "    print(f\"KS test on episode maximum BPM: Statistic = {max_bpm_ks_stat:.4f}, p-value = {max_bpm_ks_p:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
