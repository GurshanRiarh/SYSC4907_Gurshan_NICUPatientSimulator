{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab43f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6949013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Heart Rate Data\n",
    "file_path = '/home/Gurshan.R/Documents/GitHub/SYSC4907_Capstone/GAN_Heart_v2/infant_2_8h_heart_rate_outlierRem.csv'  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the heart rate column exists\n",
    "columns = ['heart_rate']  # Replace with the correct column name for heart rate\n",
    "if columns[0] not in df.columns:\n",
    "    raise ValueError(f\"Column '{columns[0]}' not found in the dataset.\")\n",
    "\n",
    "# Normalization\n",
    "data = df[columns].to_numpy().reshape(-1, 1)  # Extract heart rate data\n",
    "\n",
    "# Confirm data range\n",
    "min_data_value = data.min()\n",
    "max_data_value = data.max()\n",
    "print(f\"Data range before normalization: {min_data_value} to {max_data_value}\")\n",
    "\n",
    "# Normalize the data\n",
    "min_val, max_val = 100, 150  # Known neonate heart rate range\n",
    "data_normalized = (data - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "data_normalized = torch.tensor(data_normalized, dtype=torch.float32)\n",
    "\n",
    "# Ensure normalization was successful\n",
    "print(f\"Data range after normalization: {data_normalized.min().item()} to {data_normalized.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfe823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()  # Outputs normalized data in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        return self.model(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # Output probability of being real\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Generator and Discriminator\n",
    "noise_dim = 10\n",
    "generator = Generator(noise_dim).to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcf1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "epochs = 5000\n",
    "batch_size = 16\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66144d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    discriminator.zero_grad()\n",
    "    idx = torch.randint(0, data_normalized.size(0), (batch_size,))  # Random sampling\n",
    "    real_data = data_normalized[idx].to(device)\n",
    "    real_loss = criterion(discriminator(real_data), real_labels)\n",
    "\n",
    "    noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "    fake_data = generator(noise).detach()\n",
    "    fake_loss = criterion(discriminator(fake_data), fake_labels)\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    # Train Generator\n",
    "    generator.zero_grad()\n",
    "    noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "    fake_data = generator(noise)\n",
    "    g_loss = criterion(discriminator(fake_data), real_labels)\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # Print losses every 500 epochs\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch [{epoch}/{epochs}] D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2244f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Data\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(96, noise_dim).to(device)\n",
    "    synthetic_data = generator(noise).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bae28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize real and synthetic data for plotting\n",
    "real_data_denormalized = data_normalized.numpy() * (max_val - min_val) + min_val\n",
    "\n",
    "# If synthetic_data is already a numpy array, use it directly\n",
    "synthetic_data_denormalized = synthetic_data * (max_val - min_val) + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55027f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm denormalization\n",
    "print(f\"Real Data range after denormalization: {real_data_denormalized.min()} to {real_data_denormalized.max()}\")\n",
    "print(f\"Synthetic Data range after denormalization: {synthetic_data_denormalized.min()} to {synthetic_data_denormalized.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(real_data_denormalized, label=\"Real Data\", color=\"blue\", alpha=0.6)\n",
    "plt.plot(synthetic_data_denormalized, label=\"Synthetic Data\", color=\"orange\", linestyle=\"--\", alpha=0.8)\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Heart Rate (BPM)\")\n",
    "plt.title(\"Comparison of Real and Synthetic Neonate Heart Rate Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e45fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained generator's state dictionary\n",
    "torch.save(generator.state_dict(), 'trained_generator_HeartRate_again.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29e373",
   "metadata": {},
   "source": [
    "# EVALUATION CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative Evaluation Metrics\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, wasserstein_distance, skew, kurtosis\n",
    "\n",
    "# Flatten the denormalized data arrays\n",
    "real_flat = real_data_denormalized.flatten()\n",
    "syn_flat = synthetic_data_denormalized.flatten()\n",
    "\n",
    "# 1. Kolmogorovâ€“Smirnov (KS) Test\n",
    "ks_stat, ks_p_value = ks_2samp(real_flat, syn_flat)\n",
    "print(f\"KS Test Statistic: {ks_stat:.4f}, p-value: {ks_p_value:.4f}\")\n",
    "\n",
    "# 2. Wasserstein Distance (Earth Mover's Distance)\n",
    "w_distance = wasserstein_distance(real_flat, syn_flat)\n",
    "print(f\"Wasserstein Distance: {w_distance:.4f}\")\n",
    "\n",
    "# 3. Summary Statistics Comparison\n",
    "real_mean = np.mean(real_flat)\n",
    "real_std = np.std(real_flat)\n",
    "syn_mean = np.mean(syn_flat)\n",
    "syn_std = np.std(syn_flat)\n",
    "print(f\"Real Data Mean: {real_mean:.4f}, STD: {real_std:.4f}\")\n",
    "print(f\"Synthetic Data Mean: {syn_mean:.4f}, STD: {syn_std:.4f}\")\n",
    "\n",
    "# 4. Skewness and Kurtosis\n",
    "real_skew = skew(real_flat)\n",
    "syn_skew = skew(syn_flat)\n",
    "real_kurt = kurtosis(real_flat)\n",
    "syn_kurt = kurtosis(syn_flat)\n",
    "print(f\"Real Data Skewness: {real_skew:.4f}, Kurtosis: {real_kurt:.4f}\")\n",
    "print(f\"Synthetic Data Skewness: {syn_skew:.4f}, Kurtosis: {syn_kurt:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
